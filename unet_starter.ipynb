{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liangchow/zindi-amazon-secret-runway/blob/dylan/unet_starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bNoSnqe7aJt"
      },
      "outputs": [],
      "source": [
        "# Read this first (10-15 minutes read)\n",
        "# https://amaarora.github.io/posts/2020-09-13-unet.html\n",
        "\n",
        "# Then, read these:\n",
        "# https://pyimagesearch.com/2021/11/08/u-net-training-image-segmentation-models-in-pytorch/\n",
        "# https://www.kaggle.com/code/quadeer15sh/how-to-perform-semantic-segmentation-using-u-net/\n",
        "# https://www.kaggle.com/code/awsaf49/uwmgi-unet-train-pytorch#Class-Distribution\n",
        "# https://pytorch.org/hub/mateuszbuda_brain-segmentation-pytorch_unet/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "\n",
        "!pip install rasterio geopandas numpy matplotlib"
      ],
      "metadata": {
        "id": "r-U0qi46Frp1",
        "outputId": "b0e0e32b-115f-4bd0-ec2b-3efeacce9ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.8.30)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from rasterio) (3.1.4)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from geopandas) (24.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd"
      ],
      "metadata": {
        "id": "JhSKF2qxCcha"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sBw85nDeZd_M",
        "outputId": "ba2694f9-0ceb-4b32-a938-136575992e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CONSTANTS & CONFIGURATIONS\n",
        "\n",
        "# Set path\n",
        "path = os.path.join(\"/content\", \"drive\", \"MyDrive\", \"training\")\n",
        "\n",
        "image_path = os.path.join(path, \"images\")\n",
        "mask_path = os.path.join(path, \"masks\")\n",
        "\n",
        "# Define test split\n",
        "test_split = 0.15\n",
        "\n",
        "# Check device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "memory = True if device == \"cuda\" else False\n",
        "\n",
        "# Define number of channels, number of classes, and number of level in U-Net\n",
        "num_channels = 1\n",
        "num_classes = 1\n",
        "num_levels = 3\n",
        "\n",
        "# Define learning ratem number of epochs, and batch size\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "batch_size = 16\n",
        "\n",
        "# Define input image dimensions\n",
        "input_image_height = 512\n",
        "input_image_width = 512\n",
        "\n",
        "# Define threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# Define path to base output directory\n",
        "base_output_dir = \"output\"\n",
        "\n",
        "# Define path to output serialized model, model training plot, and test image path\n",
        "output_model_path = os.path.join(base_output_dir, \"unet_tgs_salt.pth\")\n",
        "output_plot_path = os.path.join(base_output_dir, \"plot.png\")"
      ],
      "metadata": {
        "id": "VoGB-NYd-UCp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load files\n",
        "\n",
        "BLACKLISTED_FILES = [\"Sentinel_AllBands_Training_Id_127.tif\",\"Sentinel_AllBands_Training_Id_140.tif\",\"Sentinel_AllBands_Training_Id_142.tif\",\"Sentinel_AllBands_Training_Id_174.tif\"]\n",
        "\n",
        "def load_tifs_as_arrays(image_path):\n",
        "  image_arrays = []\n",
        "  filename_map = []\n",
        "  for filename in os.listdir(image_path):\n",
        "      if filename.endswith(\".tif\") and filename not in BLACKLISTED_FILES:\n",
        "          image_filepath = os.path.join(image_path, filename)\n",
        "          with rasterio.open(image_filepath) as src:\n",
        "            img_array = src.read()\n",
        "            image_arrays.append(img_array)\n",
        "            filename_map.append(filename)\n",
        "  return image_arrays, filename_map\n",
        "\n",
        "image_arrays, filename_map = load_tifs_as_arrays(image_path)\n",
        "print(filename_map)\n"
      ],
      "metadata": {
        "id": "Ldhb0ZKmFmEB",
        "outputId": "aa271cc0-8188-4647-e9e7-05b779fd71c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sentinel_AllBands_Training_Id_1.tif', 'Sentinel_AllBands_Training_Id_2.tif', 'Sentinel_AllBands_Training_Id_9.tif', 'Sentinel_AllBands_Training_Id_10.tif', 'Sentinel_AllBands_Training_Id_11.tif', 'Sentinel_AllBands_Training_Id_17.tif', 'Sentinel_AllBands_Training_Id_18.tif', 'Sentinel_AllBands_Training_Id_19.tif', 'Sentinel_AllBands_Training_Id_20.tif', 'Sentinel_AllBands_Training_Id_21.tif', 'Sentinel_AllBands_Training_Id_22.tif', 'Sentinel_AllBands_Training_Id_23.tif', 'Sentinel_AllBands_Training_Id_28.tif', 'Sentinel_AllBands_Training_Id_30.tif', 'Sentinel_AllBands_Training_Id_31.tif', 'Sentinel_AllBands_Training_Id_32.tif', 'Sentinel_AllBands_Training_Id_33.tif', 'Sentinel_AllBands_Training_Id_36.tif', 'Sentinel_AllBands_Training_Id_37.tif', 'Sentinel_AllBands_Training_Id_38.tif', 'Sentinel_AllBands_Training_Id_39.tif', 'Sentinel_AllBands_Training_Id_40.tif', 'Sentinel_AllBands_Training_Id_41.tif', 'Sentinel_AllBands_Training_Id_42.tif', 'Sentinel_AllBands_Training_Id_44.tif', 'Sentinel_AllBands_Training_Id_45.tif', 'Sentinel_AllBands_Training_Id_46.tif', 'Sentinel_AllBands_Training_Id_55.tif', 'Sentinel_AllBands_Training_Id_56.tif', 'Sentinel_AllBands_Training_Id_57.tif', 'Sentinel_AllBands_Training_Id_58.tif', 'Sentinel_AllBands_Training_Id_59.tif', 'Sentinel_AllBands_Training_Id_60.tif', 'Sentinel_AllBands_Training_Id_61.tif', 'Sentinel_AllBands_Training_Id_62.tif', 'Sentinel_AllBands_Training_Id_63.tif', 'Sentinel_AllBands_Training_Id_64.tif', 'Sentinel_AllBands_Training_Id_66.tif', 'Sentinel_AllBands_Training_Id_68.tif', 'Sentinel_AllBands_Training_Id_69.tif', 'Sentinel_AllBands_Training_Id_71.tif', 'Sentinel_AllBands_Training_Id_73.tif', 'Sentinel_AllBands_Training_Id_74.tif', 'Sentinel_AllBands_Training_Id_75.tif', 'Sentinel_AllBands_Training_Id_76.tif', 'Sentinel_AllBands_Training_Id_77.tif', 'Sentinel_AllBands_Training_Id_78.tif', 'Sentinel_AllBands_Training_Id_79.tif', 'Sentinel_AllBands_Training_Id_65.tif', 'Sentinel_AllBands_Training_Id_67.tif', 'Sentinel_AllBands_Training_Id_85.tif', 'Sentinel_AllBands_Training_Id_88.tif', 'Sentinel_AllBands_Training_Id_89.tif', 'Sentinel_AllBands_Training_Id_98.tif', 'Sentinel_AllBands_Training_Id_99.tif', 'Sentinel_AllBands_Training_Id_100.tif', 'Sentinel_AllBands_Training_Id_101.tif', 'Sentinel_AllBands_Training_Id_102.tif', 'Sentinel_AllBands_Training_Id_103.tif', 'Sentinel_AllBands_Training_Id_105.tif', 'Sentinel_AllBands_Training_Id_106.tif', 'Sentinel_AllBands_Training_Id_107.tif', 'Sentinel_AllBands_Training_Id_108.tif', 'Sentinel_AllBands_Training_Id_110.tif', 'Sentinel_AllBands_Training_Id_111.tif', 'Sentinel_AllBands_Training_Id_114.tif', 'Sentinel_AllBands_Training_Id_115.tif', 'Sentinel_AllBands_Training_Id_118.tif', 'Sentinel_AllBands_Training_Id_120.tif', 'Sentinel_AllBands_Training_Id_121.tif', 'Sentinel_AllBands_Training_Id_123.tif', 'Sentinel_AllBands_Training_Id_124.tif', 'Sentinel_AllBands_Training_Id_125.tif', 'Sentinel_AllBands_Training_Id_126.tif', 'Sentinel_AllBands_Training_Id_130.tif', 'Sentinel_AllBands_Training_Id_131.tif', 'Sentinel_AllBands_Training_Id_132.tif', 'Sentinel_AllBands_Training_Id_135.tif', 'Sentinel_AllBands_Training_Id_136.tif', 'Sentinel_AllBands_Training_Id_137.tif', 'Sentinel_AllBands_Training_Id_138.tif', 'Sentinel_AllBands_Training_Id_139.tif', 'Sentinel_AllBands_Training_Id_141.tif', 'Sentinel_AllBands_Training_Id_143.tif', 'Sentinel_AllBands_Training_Id_144.tif', 'Sentinel_AllBands_Training_Id_145.tif', 'Sentinel_AllBands_Training_Id_146.tif', 'Sentinel_AllBands_Training_Id_147.tif', 'Sentinel_AllBands_Training_Id_148.tif', 'Sentinel_AllBands_Training_Id_149.tif', 'Sentinel_AllBands_Training_Id_150.tif', 'Sentinel_AllBands_Training_Id_151.tif', 'Sentinel_AllBands_Training_Id_152.tif', 'Sentinel_AllBands_Training_Id_154.tif', 'Sentinel_AllBands_Training_Id_155.tif', 'Sentinel_AllBands_Training_Id_156.tif', 'Sentinel_AllBands_Training_Id_157.tif', 'Sentinel_AllBands_Training_Id_160.tif', 'Sentinel_AllBands_Training_Id_161.tif', 'Sentinel_AllBands_Training_Id_162.tif', 'Sentinel_AllBands_Training_Id_163.tif', 'Sentinel_AllBands_Training_Id_165.tif', 'Sentinel_AllBands_Training_Id_169.tif', 'Sentinel_AllBands_Training_Id_172.tif', 'Sentinel_AllBands_Training_Id_175.tif', 'Sentinel_AllBands_Training_Id_176.tif', 'Sentinel_AllBands_Training_Id_179.tif', 'Sentinel_AllBands_Training_Id_182.tif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def trim_arrays(untrimmed_image_arrays):\n",
        "  trimmed_images = []\n",
        "  for image in untrimmed_image_arrays:\n",
        "    if image.shape == (9, 512, 512):\n",
        "      trimmed_images.append(image)\n",
        "      continue\n",
        "\n",
        "    if image.shape == (9, 512, 513):\n",
        "      nan_counts_front = np.sum(np.isnan(image[:, :, 0]))\n",
        "      nan_counts_back = np.sum(np.isnan(image[:, :, -1]))\n",
        "\n",
        "      if nan_counts_front > nan_counts_back:\n",
        "        trimmed_array = image[:, :, 1:]\n",
        "      else:\n",
        "        trimmed_image = image[:, :, :-1]\n",
        "      trimmed_images.append(trimmed_image)\n",
        "    else:\n",
        "      print(\"ERROR: Unexpected size detected\", image.shape)\n",
        "  return np.stack(trimmed_images)\n",
        "\n",
        "trimmed_image_arrays = trim_arrays(image_arrays)\n",
        "assert(np.sum(np.isnan(trimmed_image_arrays) == 0)) # Ensure there are no NaN values\n",
        "print(trimmed_image_arrays.shape) # (Number of Images, Channels per Image, Width of Image, Height of Image)"
      ],
      "metadata": {
        "id": "fr41U0k3zBNg",
        "outputId": "b2950289-d932-4557-e754-aeafa849798f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(108, 9, 512, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image_channels(image_arrays):\n",
        "  \"\"\"Normalizes all channels of a list of image arrays.\n",
        "\n",
        "  Args:\n",
        "    image_arrays: A list of image arrays, where each array has shape (C, H, W).\n",
        "\n",
        "  Returns:\n",
        "    A list of normalized image arrays.\n",
        "  \"\"\"\n",
        "  normalized_image_arrays = []\n",
        "  for image in image_arrays:\n",
        "    normalized_image = []\n",
        "    for channel in image:\n",
        "        # Normalize the channel\n",
        "        channel_min = np.nanmin(channel)\n",
        "        channel_max = np.nanmax(channel)\n",
        "        normalized_channel = (channel - channel_min) / (channel_max - channel_min)\n",
        "        normalized_image.append(normalized_channel)\n",
        "    normalized_image_arrays.append(normalized_image)\n",
        "\n",
        "  return np.stack(normalized_image_arrays)\n",
        "\n",
        "normalized_image_arrays = normalize_image_channels(trimmed_image_arrays)\n",
        "print(normalized_image_arrays.shape)"
      ],
      "metadata": {
        "id": "-tAOAzLvJPBD",
        "outputId": "2aed95fb-80f9-42f3-a36c-63f8a773fc1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(108, 9, 512, 512)\n"
          ]
        }
      ]
    }
  ]
}